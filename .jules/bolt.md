## 2024-05-24 - Amortized O(1) Dynamic Array Resizing for NumPy VectorStore
**Learning:** In purely NumPy-based vector stores (such as the fallback implementation in Pinak Memory Service), sequentially adding vectors using `np.vstack` and `np.concatenate` has an O(NÂ²) time complexity. This occurs because every individual insert operation must re-allocate a new array and copy all existing elements over, which creates a significant bottleneck when sequentially ingesting data or recovering from the SQLite DB.
**Action:** Always prefer maintaining pre-allocated arrays with a `capacity` and a `size` tracker. When the capacity is exceeded, dynamically double it (amortized O(1) insertion). Use sliced views (e.g., `self.vectors[:self.size]`) for all read operations like `search` or `save` to ensure correct behavior without exposing the uninitialized buffer. This straightforward change yielded an ~40% reduction in sequential ingestion time for 2000 vectors.
